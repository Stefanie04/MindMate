{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stefanie04/MindMate/blob/main/Notebook_Stefanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztUshbsm_kZa"
      },
      "source": [
        "# Start ‚ñ∂"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FWRTQc9_eHj",
        "outputId": "ff214da6-bfa5-416e-bbd0-151182e04acb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\sdonthi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, date\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import json\n",
        "\n",
        "import io\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "import tqdm\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "weJWzjDZ_qNu"
      },
      "outputs": [],
      "source": [
        "with open('Dataset/intents-rev2.json', 'r') as f:\n",
        "    json_string = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfy0p3N6_6VS"
      },
      "source": [
        "# Preperation of the dataset üöß"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7M5rMZsbACxS"
      },
      "outputs": [],
      "source": [
        "json_dict = json.loads(json_string)\n",
        "intents = json_dict['intents']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ny-qKe6LAHp-"
      },
      "outputs": [],
      "source": [
        "tags = []\n",
        "patterns = []\n",
        "responses = {}\n",
        "for intents in json_dict['intents']:\n",
        "    responses[intents['tag']]=intents['responses']\n",
        "    for lines in intents['patterns']:\n",
        "      patterns.append(lines)\n",
        "      tags.append(intents['tag'])\n",
        "json_df = pd.DataFrame({'tags':tags, 'patterns':patterns})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcOhojwWA0KN"
      },
      "source": [
        "# Pre-Processing üèó"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUsR6-jdA8P3"
      },
      "source": [
        "## Lowercases / removing punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OopZrjvfA7tb",
        "outputId": "58886684-afd7-4be9-f4ea-354eeb522ff2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sdonthi\\AppData\\Local\\Temp/ipykernel_18300/1545242841.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  pre_df = pre_df.apply(lambda x: x.astype(str).str.replace('[{}]'.format(string.punctuation),''))\n"
          ]
        }
      ],
      "source": [
        "pre_df = json_df.apply(lambda x: x.astype(str).str.lower())\n",
        "\n",
        "import string\n",
        "pre_df = pre_df.apply(lambda x: x.astype(str).str.replace('[{}]'.format(string.punctuation),''))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4YJZtSRBKSV"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "y41cOYtjBI-V"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# Create a Tokenizer object\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(pre_df['patterns'])\n",
        "tokenized_text = tokenizer.texts_to_sequences(pre_df['patterns'])\n",
        "\n",
        "with open('tokenizer.pkl', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(tokenized_text)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Create a LabelEncoder object\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(pre_df['tags'])\n",
        "\n",
        "#exporting the departure encoder\n",
        "output = open('encoder.pkl', 'wb')\n",
        "pickle.dump(encoder, output)\n",
        "output.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "pre_df.to_pickle('pre_df.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBy1e1w6Bksk",
        "outputId": "e5c6b5ef-9db7-431c-98f9-3fa52a7e0dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 443 unique tokens.\n"
          ]
        }
      ],
      "source": [
        "# Creating the word list\n",
        "word_index = tokenizer.word_index\n",
        "print(\"Found %s unique tokens.\" % len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvelbXz8B6l-",
        "outputId": "29136beb-5867-4c19-e6d6-8e636c6a06ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(330, 21)\n",
            "(330,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EL-ywK9JenS",
        "outputId": "100c5d6a-e64b-4606-962c-ea3e9a085b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output length:  166\n"
          ]
        }
      ],
      "source": [
        "output_length = encoder.classes_.shape[0]\n",
        "print('Output length: ', output_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqi7mBtqCFQ1"
      },
      "source": [
        "# Model üï∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w2KFFKWMGZue"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Embedding, LSTM, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nWSHMWOUGfne"
      },
      "outputs": [],
      "source": [
        "input_size = x_train.shape[1]\n",
        "output_size = encoder.classes_.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_size=21,output_size=166\n"
          ]
        }
      ],
      "source": [
        "print(\"input_size=\" + str(input_size) + \",output_size=\"+str(output_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mUDm5DpyGh7U"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, 16, input_shape=(input_size,)))\n",
        "model.add(LSTM(16, return_sequences=True))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(output_length, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tkh3vnGmGklT"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eiREB_pGnsJ",
        "outputId": "f2c1b34f-809a-46e2-d368-6c215c5a5404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 2s 11ms/step - loss: 5.1034 - accuracy: 0.0152\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 5.0178 - accuracy: 0.0212\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.8282 - accuracy: 0.0273\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.7731 - accuracy: 0.0303\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.7315 - accuracy: 0.0212\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.7000 - accuracy: 0.0364\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.6397 - accuracy: 0.0394\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.5831 - accuracy: 0.0424\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 4.5070 - accuracy: 0.0333\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.4418 - accuracy: 0.0394\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.3555 - accuracy: 0.0424\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.2707 - accuracy: 0.0485\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 4.2050 - accuracy: 0.0545\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.1269 - accuracy: 0.0545\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.0780 - accuracy: 0.0636\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 4.0144 - accuracy: 0.0697\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.9355 - accuracy: 0.0697\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.9003 - accuracy: 0.0697\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.8256 - accuracy: 0.0758\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.7744 - accuracy: 0.0667\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.7048 - accuracy: 0.0636\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.6852 - accuracy: 0.0879\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.6117 - accuracy: 0.0939\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.5907 - accuracy: 0.0879\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.5376 - accuracy: 0.1061\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.4738 - accuracy: 0.0848\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.4314 - accuracy: 0.1000\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.4151 - accuracy: 0.0970\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.3600 - accuracy: 0.1152\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.3049 - accuracy: 0.1121\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.3225 - accuracy: 0.1030\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.2562 - accuracy: 0.1394\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.2068 - accuracy: 0.1727\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.1655 - accuracy: 0.1273\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.1581 - accuracy: 0.1636\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.0935 - accuracy: 0.1545\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.0445 - accuracy: 0.1848\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.0155 - accuracy: 0.1818\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.9580 - accuracy: 0.1848\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.9140 - accuracy: 0.2030\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.8842 - accuracy: 0.2152\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.8210 - accuracy: 0.2364\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.8357 - accuracy: 0.2091\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.7443 - accuracy: 0.2121\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.7200 - accuracy: 0.2424\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.6883 - accuracy: 0.2455\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.6612 - accuracy: 0.2455\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.6269 - accuracy: 0.2364\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.5815 - accuracy: 0.2758\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.5216 - accuracy: 0.2727\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.5172 - accuracy: 0.2788\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.4730 - accuracy: 0.2909\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.4041 - accuracy: 0.3273\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.3648 - accuracy: 0.2879\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.3272 - accuracy: 0.3364\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.2982 - accuracy: 0.3333\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.2683 - accuracy: 0.3152\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.2231 - accuracy: 0.3152\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.1948 - accuracy: 0.3545\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.1952 - accuracy: 0.3667\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.1646 - accuracy: 0.3667\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.1374 - accuracy: 0.3606\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.1267 - accuracy: 0.3424\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.0855 - accuracy: 0.3939\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.0501 - accuracy: 0.3970\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.0060 - accuracy: 0.4121\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.9865 - accuracy: 0.4030\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.9956 - accuracy: 0.3788\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.9341 - accuracy: 0.4212\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.9263 - accuracy: 0.4424\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.8986 - accuracy: 0.4606\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.8584 - accuracy: 0.4424\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.8269 - accuracy: 0.4727\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.8005 - accuracy: 0.4606\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.8116 - accuracy: 0.4636\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.7667 - accuracy: 0.4636\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.7501 - accuracy: 0.4727\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.7392 - accuracy: 0.4788\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.7038 - accuracy: 0.4939\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.6689 - accuracy: 0.5000\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.6428 - accuracy: 0.5273\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.6556 - accuracy: 0.4939\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.6366 - accuracy: 0.5000\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.6250 - accuracy: 0.5303\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.6064 - accuracy: 0.5182\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.5801 - accuracy: 0.5152\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.5440 - accuracy: 0.5212\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.5597 - accuracy: 0.5364\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.5295 - accuracy: 0.5242\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.4584 - accuracy: 0.5909\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.4902 - accuracy: 0.5606\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.4467 - accuracy: 0.5727\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.4660 - accuracy: 0.5364\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.4628 - accuracy: 0.5788\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.4193 - accuracy: 0.5970\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.3852 - accuracy: 0.5848\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.3730 - accuracy: 0.6030\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.3526 - accuracy: 0.5939\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.3311 - accuracy: 0.6000\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.3540 - accuracy: 0.5970\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.3466 - accuracy: 0.5909\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.2560 - accuracy: 0.6273\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.2747 - accuracy: 0.6000\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.2621 - accuracy: 0.6394\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.2593 - accuracy: 0.6152\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.2462 - accuracy: 0.6303\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.2077 - accuracy: 0.6303\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.2183 - accuracy: 0.6182\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1968 - accuracy: 0.6152\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1879 - accuracy: 0.6212\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.1645 - accuracy: 0.6455\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1608 - accuracy: 0.6485\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1286 - accuracy: 0.6788\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.1393 - accuracy: 0.6545\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1258 - accuracy: 0.6879\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1043 - accuracy: 0.6758\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.0800 - accuracy: 0.6788\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0845 - accuracy: 0.6606\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.0636 - accuracy: 0.6697\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0738 - accuracy: 0.6818\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.0237 - accuracy: 0.7091\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0248 - accuracy: 0.6909\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0587 - accuracy: 0.6606\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0302 - accuracy: 0.6970\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.0327 - accuracy: 0.6667\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0071 - accuracy: 0.6818\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.9847 - accuracy: 0.7091\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9878 - accuracy: 0.7152\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.9699 - accuracy: 0.6939\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9662 - accuracy: 0.6788\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9212 - accuracy: 0.7030\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.9226 - accuracy: 0.7364\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9132 - accuracy: 0.7152\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9265 - accuracy: 0.7030\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9026 - accuracy: 0.7182\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9048 - accuracy: 0.7273\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.8761 - accuracy: 0.7182\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8954 - accuracy: 0.7303\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8825 - accuracy: 0.7061\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8664 - accuracy: 0.7212\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8522 - accuracy: 0.7636\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8644 - accuracy: 0.7303\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8319 - accuracy: 0.7424\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.8640 - accuracy: 0.7212\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8449 - accuracy: 0.7394\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.8161 - accuracy: 0.7333\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8281 - accuracy: 0.7485\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7916 - accuracy: 0.7636\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8137 - accuracy: 0.7394\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7805 - accuracy: 0.7364\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7891 - accuracy: 0.7576\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7812 - accuracy: 0.7515\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7803 - accuracy: 0.7545\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7718 - accuracy: 0.7576\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7515 - accuracy: 0.7697\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7535 - accuracy: 0.7515\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7499 - accuracy: 0.7606\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7424 - accuracy: 0.7545\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7357 - accuracy: 0.7636\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7161 - accuracy: 0.7818\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7117 - accuracy: 0.7879\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7243 - accuracy: 0.7758\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7105 - accuracy: 0.7545\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.7053 - accuracy: 0.7818\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7040 - accuracy: 0.7727\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6883 - accuracy: 0.8121\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6754 - accuracy: 0.7818\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.7697\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6738 - accuracy: 0.8061\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6846 - accuracy: 0.8030\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6679 - accuracy: 0.7879\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6707 - accuracy: 0.7636\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6630 - accuracy: 0.7909\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6488 - accuracy: 0.8000\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6335 - accuracy: 0.7939\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6126 - accuracy: 0.8091\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6433 - accuracy: 0.7848\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6287 - accuracy: 0.7970\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6238 - accuracy: 0.8273\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6265 - accuracy: 0.8152\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6468 - accuracy: 0.7818\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5904 - accuracy: 0.8394\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5918 - accuracy: 0.8152\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6077 - accuracy: 0.7879\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5770 - accuracy: 0.8364\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5845 - accuracy: 0.8273\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5589 - accuracy: 0.8273\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5725 - accuracy: 0.8152\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5696 - accuracy: 0.8152\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5664 - accuracy: 0.8394\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5843 - accuracy: 0.7939\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5663 - accuracy: 0.8182\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5777 - accuracy: 0.8424\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5783 - accuracy: 0.8152\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5329 - accuracy: 0.8333\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5603 - accuracy: 0.8364\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5417 - accuracy: 0.8212\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5420 - accuracy: 0.8394\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5406 - accuracy: 0.8394\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5238 - accuracy: 0.8455\n"
          ]
        }
      ],
      "source": [
        "train = model.fit(x_train, y_train, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Tun-lFwyGvA5",
        "outputId": "a037b564-739b-499e-fa06-d2dee95470ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x28c8cb7b7f0>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train.history['accuracy'], label='training set accuracy')\n",
        "plt.plot(train.history['loss'], label='trainig set loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "xf4pnvfjsgHm",
        "outputId": "7cc51a23-181b-44b9-ca84-c45d9b719760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Otx0zNjQ-X"
      },
      "source": [
        "#Chatbot ü§ñ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Pjw-gEje9a",
        "outputId": "a164871f-31f1-4594-b491-89846d2ce4c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 431ms/step\n",
            "response=greeting\n",
            "Pocket Therapist:  Great to see you. How do you feel currently?\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "response=about\n",
            "Pocket Therapist:  You can call me MindMate.\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "response=about\n",
            "Pocket Therapist:  I'm MindMate. I am a conversational agent designed to mimic a therapist. So how are you feeling today?\n",
            "1/1 [==============================] - 0s 12ms/step\n",
            "response=casual\n",
            "Pocket Therapist:  Tell me more\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "response=casual\n",
            "Pocket Therapist:  Come elucidate your thoughts\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "response=casual\n",
            "Pocket Therapist:  How were you feeling last week?\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "response=casual\n",
            "Pocket Therapist:  Tell me more\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "response=casual\n",
            "Pocket Therapist:  I'm listening. Please go on.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18300/2943926275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[0mconversation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0muser_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'User: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bye'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Goodbye and take care.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\sdonthi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             )\n\u001b[1;32m-> 1006\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\sdonthi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  conversation = []\n",
        "  user_input = input('User: ')\n",
        "  if user_input == 'bye':\n",
        "    print('Goodbye and take care.')\n",
        "    break\n",
        "\n",
        "  # converting lowercase / removing punctuation \n",
        "  user_input = user_input.lower()\n",
        "  user_input = re.sub(r'[^\\w\\s]', '', user_input)\n",
        "  conversation.append(user_input)\n",
        "\n",
        "  # tokenizer / padding\n",
        "  user_input = tokenizer.texts_to_sequences(conversation)\n",
        "  user_input = np.array(user_input).reshape(-1)\n",
        "  user_input = pad_sequences([user_input], input_size)\n",
        "\n",
        "  # output\n",
        "  output = model.predict(user_input)\n",
        "  output = output.argmax()\n",
        "\n",
        "  # prediction\n",
        "  response = encoder.inverse_transform([output])[0]\n",
        "  print('response=' + response)\n",
        "  if response in responses:\n",
        "    print('Pocket Therapist: ', random.choice(responses[response]))\n",
        "  else:\n",
        "    print('Sorry, I do not understand. Can you please rephrase?')\n",
        "  if response == 'goodbye':\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('mindmate_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "# loading\n",
        "#my_dir = os.path.dirname(__file__)\n",
        "tokenizer1 = None\n",
        "#model_path = os.path.join(my_dir, 'mindmate_model.h5')\n",
        "with open('tokenizer.pkl', 'rb') as handle:\n",
        "    tokenizer1 = pickle.load(handle)\n",
        "\n",
        "#model_path = os.path.join(my_dir, 'mindmate_model.h5')\n",
        "pkl_file = open('encoder.pkl', 'rb')\n",
        "le = pickle.load(pkl_file) \n",
        "pkl_file.close()\n",
        "\n",
        "#model_path = os.path.join(my_dir, 'mindmate_model.h5')\n",
        "model = keras.models.load_model('mindmate_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 421ms/step\n",
            "response=greeting\n",
            "Pocket Therapist:  Hello there. Glad to see you're back. What's going on in your world right now?\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "response=greeting\n",
            "Pocket Therapist:  Hello there. Tell me how are you feeling today?\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "response=about\n",
            "Pocket Therapist:  I'm MindMate, your Personal Therapeutic AI Assistant. How are you feeling today\n",
            "Goodbye and take care.\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  conversation = []\n",
        "  input_size=21\n",
        "  output_size=166\n",
        "  user_input = input('User: ')\n",
        "  if user_input == 'bye':\n",
        "    print('Goodbye and take care.')\n",
        "    break\n",
        "\n",
        "  # converting lowercase / removing punctuation \n",
        "  user_input = user_input.lower()\n",
        "  user_input = re.sub(r'[^\\w\\s]', '', user_input)\n",
        "  conversation.append(user_input)\n",
        "\n",
        "  # tokenizer / padding\n",
        "  user_input = tokenizer1.texts_to_sequences(conversation)\n",
        "  user_input = np.array(user_input).reshape(-1)\n",
        "  user_input = pad_sequences([user_input], input_size)\n",
        "\n",
        "  # output\n",
        "  output = model.predict(user_input)\n",
        "  output = output.argmax()\n",
        "\n",
        "  # prediction\n",
        "  response = le.inverse_transform([output])[0]\n",
        "  print('response=' + response)\n",
        "  if response in responses:\n",
        "    print('Pocket Therapist: ', random.choice(responses[response]))\n",
        "  else:\n",
        "    print('Sorry, I do not understand. Can you please rephrase?')\n",
        "  if response == 'goodbye':\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfj1S++BgK4adIe4e88ScI",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "dc40aa98bc857e6b44b78fb1f886858e51ffa17b4908ef3c7ccadfa45af47b27"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stefanie04/MindMate/blob/main/Notebook_Stefanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztUshbsm_kZa"
      },
      "source": [
        "# Start ‚ñ∂"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FWRTQc9_eHj",
        "outputId": "ff214da6-bfa5-416e-bbd0-151182e04acb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\sdonthi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, date\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import json\n",
        "\n",
        "import io\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "weJWzjDZ_qNu"
      },
      "outputs": [],
      "source": [
        "with open('Dataset/intents-rev2.json', 'r') as f:\n",
        "    json_string = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfy0p3N6_6VS"
      },
      "source": [
        "# Preperation of the dataset üöß"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7M5rMZsbACxS"
      },
      "outputs": [],
      "source": [
        "json_dict = json.loads(json_string)\n",
        "intents = json_dict['intents']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4VTv7tx_AFr6"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(intents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ny-qKe6LAHp-"
      },
      "outputs": [],
      "source": [
        "tags = []\n",
        "patterns = []\n",
        "responses = {}\n",
        "for intents in json_dict['intents']:\n",
        "    responses[intents['tag']]=intents['responses']\n",
        "    for lines in intents['patterns']:\n",
        "      patterns.append(lines)\n",
        "      tags.append(intents['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R4TbQnACASZO"
      },
      "outputs": [],
      "source": [
        "json_df = pd.DataFrame({'tags':tags, 'patterns':patterns})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SmdjoEL8M49y"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', json_df.shape[0]+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJk2ZzRTAUpM",
        "outputId": "f65207e5-32bd-4fc4-eb57-800ec3f8e05e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                                               greeting\n",
              "1                                               greeting\n",
              "2                                               greeting\n",
              "3                                               greeting\n",
              "4                                               greeting\n",
              "5                                               greeting\n",
              "6                                               greeting\n",
              "7                                               greeting\n",
              "8                                               greeting\n",
              "9                                               greeting\n",
              "10                                              greeting\n",
              "11                                              greeting\n",
              "12                                               morning\n",
              "13                                             afternoon\n",
              "14                                               evening\n",
              "15                                                 night\n",
              "16                                               goodbye\n",
              "17                                               goodbye\n",
              "18                                               goodbye\n",
              "19                                               goodbye\n",
              "20                                               goodbye\n",
              "21                                               goodbye\n",
              "22                                               goodbye\n",
              "23                                               goodbye\n",
              "24                                                thanks\n",
              "25                                                thanks\n",
              "26                                                thanks\n",
              "27                                                thanks\n",
              "28                                                thanks\n",
              "29                                            noresponse\n",
              "30                                       neutralresponse\n",
              "31                                                 about\n",
              "32                                                 about\n",
              "33                                                 about\n",
              "34                                                 about\n",
              "35                                                 about\n",
              "36                                                 about\n",
              "37                                                 about\n",
              "38                                                 about\n",
              "39                                                 skill\n",
              "40                                              creation\n",
              "41                                              creation\n",
              "42                                              creation\n",
              "43                                                  name\n",
              "44                                                  name\n",
              "45                                                  name\n",
              "46                                                  help\n",
              "47                                                  help\n",
              "48                                                  help\n",
              "49                                                  help\n",
              "50                                                  help\n",
              "51                                                  help\n",
              "52                                                  help\n",
              "53                                                   sad\n",
              "54                                                   sad\n",
              "55                                                   sad\n",
              "56                                                   sad\n",
              "57                                                   sad\n",
              "58                                                   sad\n",
              "59                                                   sad\n",
              "60                                                   sad\n",
              "61                                              stressed\n",
              "62                                              stressed\n",
              "63                                              stressed\n",
              "64                                              stressed\n",
              "65                                              stressed\n",
              "66                                             worthless\n",
              "67                                             worthless\n",
              "68                                             worthless\n",
              "69                                             worthless\n",
              "70                                             worthless\n",
              "71                                             depressed\n",
              "72                                             depressed\n",
              "73                                             depressed\n",
              "74                                             depressed\n",
              "75                                                 happy\n",
              "76                                                 happy\n",
              "77                                                 happy\n",
              "78                                                 happy\n",
              "79                                                 happy\n",
              "80                                                 happy\n",
              "81                                                 happy\n",
              "82                                                casual\n",
              "83                                                casual\n",
              "84                                                casual\n",
              "85                                                casual\n",
              "86                                                casual\n",
              "87                                                casual\n",
              "88                                                casual\n",
              "89                                                casual\n",
              "90                                                casual\n",
              "91                                                casual\n",
              "92                                                casual\n",
              "93                                               anxious\n",
              "94                                               anxious\n",
              "95                                            nottalking\n",
              "96                                            nottalking\n",
              "97                                            nottalking\n",
              "98                                            nottalking\n",
              "99                                                 sleep\n",
              "100                                                sleep\n",
              "101                                                sleep\n",
              "102                                                sleep\n",
              "103                                                sleep\n",
              "104                                                sleep\n",
              "105                                               scared\n",
              "106                                               scared\n",
              "107                                               scared\n",
              "108                                               scared\n",
              "109                                                death\n",
              "110                                                death\n",
              "111                                                death\n",
              "112                                                death\n",
              "113                                                death\n",
              "114                                                death\n",
              "115                                           understand\n",
              "116                                           understand\n",
              "117                                           understand\n",
              "118                                           understand\n",
              "119                                           understand\n",
              "120                                           understand\n",
              "121                                                 done\n",
              "122                                                 done\n",
              "123                                                 done\n",
              "124                                                 done\n",
              "125                                                 done\n",
              "126                                              suicide\n",
              "127                                              suicide\n",
              "128                                              suicide\n",
              "129                                              suicide\n",
              "130                                              suicide\n",
              "131                                              hateyou\n",
              "132                                              hateyou\n",
              "133                                              hateyou\n",
              "134                                               hateme\n",
              "135                                               hateme\n",
              "136                                               hateme\n",
              "137                                              default\n",
              "138                                              default\n",
              "139                                              default\n",
              "140                                              default\n",
              "141                                              default\n",
              "142                                              default\n",
              "143                                              default\n",
              "144                                              default\n",
              "145                                                jokes\n",
              "146                                                jokes\n",
              "147                                               repeat\n",
              "148                                               repeat\n",
              "149                                               repeat\n",
              "150                                                wrong\n",
              "151                                                wrong\n",
              "152                                                wrong\n",
              "153                                                wrong\n",
              "154                                               stupid\n",
              "155                                               stupid\n",
              "156                                               stupid\n",
              "157                                               stupid\n",
              "158                                             location\n",
              "159                                             location\n",
              "160                                             location\n",
              "161                                        somethingelse\n",
              "162                                        somethingelse\n",
              "163                                        somethingelse\n",
              "164                                        somethingelse\n",
              "165                                              friends\n",
              "166                                                  ask\n",
              "167                                              problem\n",
              "168                                              problem\n",
              "169                                           noapproach\n",
              "170                                           noapproach\n",
              "171                                           noapproach\n",
              "172                                            learnmore\n",
              "173                                            learnmore\n",
              "174                                            learnmore\n",
              "175                                            useragree\n",
              "176                                            useragree\n",
              "177                                           meditation\n",
              "178                                           meditation\n",
              "179                                       usermeditation\n",
              "180                                       usermeditation\n",
              "181                                        pandorauseful\n",
              "182                                           useradvice\n",
              "183                                           useradvice\n",
              "184                                           useradvice\n",
              "185                                    learnmentalhealth\n",
              "186                                    learnmentalhealth\n",
              "187                                    learnmentalhealth\n",
              "188                                     mentalhealthfact\n",
              "189                                     mentalhealthfact\n",
              "190                               definitionmentalhealth\n",
              "191                               definitionmentalhealth\n",
              "192                               importancementalhealth\n",
              "193                               importancementalhealth\n",
              "194                                 definitiondepression\n",
              "195                                 definitiondepression\n",
              "196                                           depression\n",
              "197                                           depression\n",
              "198                                           depression\n",
              "199                                           depression\n",
              "200                                  definitiontherapist\n",
              "201                                  definitiontherapist\n",
              "202                                    definitiontherapy\n",
              "203                                    definitiontherapy\n",
              "204                                    definitiontherapy\n",
              "205                              definitionmentalillness\n",
              "206                                   affectmetalillness\n",
              "207                                  causesmentalillness\n",
              "208                                   signsmentalillness\n",
              "209                                 recovermentalillness\n",
              "210                             tosymptomsmentaldisorder\n",
              "211                                             findhelp\n",
              "212                                     treatmentoptions\n",
              "213                                  involvedintreatment\n",
              "214                  differencementalhealthprofessionals\n",
              "215                                           stresswork\n",
              "216                                           stresswork\n",
              "217                                            bullywork\n",
              "218                                            wherehelp\n",
              "219                                        newmedication\n",
              "220                                          findtherapy\n",
              "221                                mentalhealthtreatment\n",
              "222              differenttypesmentalhealthprofessionals\n",
              "223                                         supportgroup\n",
              "224                                  preventmentalhealth\n",
              "225                              curementalhealthproblem\n",
              "226                              curementalhealthproblem\n",
              "227                             causmentalhealthproblems\n",
              "228                                              worried\n",
              "229                                               unwell\n",
              "230                                    socialconnections\n",
              "231                                        anxietystress\n",
              "232                                    sadnessdepression\n",
              "233                                    sadnessdepression\n",
              "234                                    meanmentalillness\n",
              "235                                  affectmentalillness\n",
              "236                                  causesmentalillness\n",
              "237                                   signsmentalillness\n",
              "238                                 recovermentalillness\n",
              "239                                   todomentaldisorder\n",
              "240                         findmentalhealthprofessional\n",
              "241                                     treatmentoptions\n",
              "242                                    involvedtreatment\n",
              "243                  differencementalhealthprofessionals\n",
              "244                       findmentalhealthprofessionalII\n",
              "245                                  involvedtreatmentII\n",
              "246                                                 help\n",
              "247                                        newmedication\n",
              "248                               feelingaftermedication\n",
              "249                                 helppayingmedication\n",
              "250                                          findtherapy\n",
              "251                           learnmentalhealthtreatment\n",
              "252                differencementalhealthprofessionalsII\n",
              "253                                     findsupportgroup\n",
              "254                                    findinpatientcare\n",
              "255                                     fintlocalservice\n",
              "256                                   learnclinicaltrias\n",
              "257                                             learnPAD\n",
              "258                               definitionmentalhealth\n",
              "259                                    supportdoesntwork\n",
              "260                          preventmentalhealthproblems\n",
              "261                            curesmentalhealthproblems\n",
              "262                           causesmentalhealthproblems\n",
              "263                                  worriedmentalhealth\n",
              "264                                        feelingunwell\n",
              "265                                        worriedfriend\n",
              "266                                      tellingwhattodo\n",
              "267                                         keepinformed\n",
              "268                                    healthinformation\n",
              "269                                                 plan\n",
              "270                                    socialconnectiosn\n",
              "271                               takecarephysicalhealth\n",
              "272                                       usedistraction\n",
              "273                                              reframe\n",
              "274                               challengethinkingtraps\n",
              "275                                          managegrief\n",
              "276                   finddoctorpsychiatristpsychologist\n",
              "277                                      seepsychiatrist\n",
              "278                                      seepsychologist\n",
              "279                                        seecounsellor\n",
              "280                                     findgroupsupport\n",
              "281                                    childyouthservice\n",
              "282                                       adultsfindhelp\n",
              "283                               findselfhelpdepression\n",
              "284                                  findselfhelpanxiety\n",
              "285                                             findhelp\n",
              "286                                         substanceuse\n",
              "287                                      freecounselling\n",
              "288                    helppayingprescriptionmedications\n",
              "289                                  paymentalhealthcare\n",
              "290                                applyincomeassistance\n",
              "291                                                  MSP\n",
              "292                                             referral\n",
              "293                   differencepsychiatristpsychologist\n",
              "294                   differencepsychotherapycounselling\n",
              "295                                     differenceCBTDBT\n",
              "296                            differenceantidepressants\n",
              "297                                    diagnosisquestion\n",
              "298                                   medicationdontwork\n",
              "299                                       personseemsill\n",
              "300                                 worriedchildteenager\n",
              "301                               informationbraininjury\n",
              "302                                lovedpersondepression\n",
              "303                             lovedpersonschizophrenia\n",
              "304                                  parentsmentalillnes\n",
              "305                                              suicide\n",
              "306                        differencementalhealthillness\n",
              "307                                informationdepression\n",
              "308                     differenceanxietyanxietydisorder\n",
              "309                              differenceanxietystress\n",
              "310                          differencesadnessdepression\n",
              "311                        dysthymiapersistentdepressive\n",
              "312                                  cyclothymicdisorder\n",
              "313                                         rapidcycling\n",
              "314                            informationhelpborderline\n",
              "315                                     schizoiddisorder\n",
              "316                                   antisocialdisorder\n",
              "317                          obsessivecompulsivedisorder\n",
              "318                                  bingeeatingdisorder\n",
              "319    differencedissociativeidentitydisorderschizoph...\n",
              "320                     differencepsychosisschizophrenia\n",
              "321                             positivenegativesymptoms\n",
              "322                                             prodrome\n",
              "323                                            ADHDadult\n",
              "324                      differencesubstanceuseaddiction\n",
              "325                                   helpalcoholdruguse\n",
              "326                                      drinkingtoomuch\n",
              "327                                    convincekidsdrugs\n",
              "328                                               cbdoil\n",
              "329                                               vaping\n",
              "Name: tags, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "json_df['tags']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcOhojwWA0KN"
      },
      "source": [
        "# Pre-Processing üèó"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUsR6-jdA8P3"
      },
      "source": [
        "## Lowercases / removing punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OopZrjvfA7tb",
        "outputId": "58886684-afd7-4be9-f4ea-354eeb522ff2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sdonthi\\AppData\\Local\\Temp/ipykernel_17504/1545242841.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  pre_df = pre_df.apply(lambda x: x.astype(str).str.replace('[{}]'.format(string.punctuation),''))\n"
          ]
        }
      ],
      "source": [
        "pre_df = json_df.apply(lambda x: x.astype(str).str.lower())\n",
        "\n",
        "import string\n",
        "pre_df = pre_df.apply(lambda x: x.astype(str).str.replace('[{}]'.format(string.punctuation),''))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4YJZtSRBKSV"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y41cOYtjBI-V"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# Create a Tokenizer object\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(pre_df['patterns'])\n",
        "tokenized_text = tokenizer.texts_to_sequences(pre_df['patterns'])\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(tokenized_text)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Create a LabelEncoder object\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(pre_df['tags'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "pre_df.to_pickle('pre_df.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBy1e1w6Bksk",
        "outputId": "e5c6b5ef-9db7-431c-98f9-3fa52a7e0dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 443 unique tokens.\n"
          ]
        }
      ],
      "source": [
        "# Creating the word list\n",
        "word_index = tokenizer.word_index\n",
        "print(\"Found %s unique tokens.\" % len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvelbXz8B6l-",
        "outputId": "29136beb-5867-4c19-e6d6-8e636c6a06ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(330, 21)\n",
            "(330,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EL-ywK9JenS",
        "outputId": "100c5d6a-e64b-4606-962c-ea3e9a085b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output length:  166\n"
          ]
        }
      ],
      "source": [
        "output_length = encoder.classes_.shape[0]\n",
        "print('Output length: ', output_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqi7mBtqCFQ1"
      },
      "source": [
        "# Model üï∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "w2KFFKWMGZue"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Embedding, LSTM, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nWSHMWOUGfne"
      },
      "outputs": [],
      "source": [
        "input_size = x_train.shape[1]\n",
        "output_size = encoder.classes_.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mUDm5DpyGh7U"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, 16, input_shape=(input_size,)))\n",
        "model.add(LSTM(16, return_sequences=True))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(output_length, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tkh3vnGmGklT"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eiREB_pGnsJ",
        "outputId": "f2c1b34f-809a-46e2-d368-6c215c5a5404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6742 - accuracy: 0.7788\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.7758\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6787 - accuracy: 0.7788\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6362 - accuracy: 0.7879\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6531 - accuracy: 0.7970\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6361 - accuracy: 0.7970\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6371 - accuracy: 0.7758\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6187 - accuracy: 0.7879\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.6135 - accuracy: 0.7970\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6105 - accuracy: 0.8061\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6229 - accuracy: 0.7788\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6257 - accuracy: 0.7939\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6116 - accuracy: 0.8030\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5950 - accuracy: 0.8212\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6269 - accuracy: 0.8000\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6135 - accuracy: 0.7939\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6246 - accuracy: 0.7909\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6137 - accuracy: 0.8182\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5869 - accuracy: 0.8242\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5753 - accuracy: 0.7909\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6010 - accuracy: 0.7970\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5935 - accuracy: 0.7970\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5734 - accuracy: 0.8182\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5736 - accuracy: 0.8212\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5906 - accuracy: 0.8182\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5854 - accuracy: 0.7636\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5736 - accuracy: 0.7909\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5703 - accuracy: 0.8121\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5654 - accuracy: 0.8000\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5484 - accuracy: 0.8364\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5568 - accuracy: 0.8182\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5658 - accuracy: 0.7788\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5391 - accuracy: 0.8303\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5678 - accuracy: 0.8091\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5269 - accuracy: 0.8182\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5371 - accuracy: 0.8152\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.5501 - accuracy: 0.7970\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5385 - accuracy: 0.8152\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5374 - accuracy: 0.8333\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5376 - accuracy: 0.8091\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5397 - accuracy: 0.8182\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5430 - accuracy: 0.8152\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5442 - accuracy: 0.8030\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5099 - accuracy: 0.8273\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5412 - accuracy: 0.8212\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5213 - accuracy: 0.8121\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5154 - accuracy: 0.8242\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4969 - accuracy: 0.8455\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5021 - accuracy: 0.8303\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4851 - accuracy: 0.8485\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5019 - accuracy: 0.8333\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.5154 - accuracy: 0.8303\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5030 - accuracy: 0.8364\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5053 - accuracy: 0.8424\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4810 - accuracy: 0.8515\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4851 - accuracy: 0.8030\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4754 - accuracy: 0.8394\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4902 - accuracy: 0.8394\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4772 - accuracy: 0.8333\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4742 - accuracy: 0.8424\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4769 - accuracy: 0.8485\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4656 - accuracy: 0.8333\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4875 - accuracy: 0.8455\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4750 - accuracy: 0.8424\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4592 - accuracy: 0.8303\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4988 - accuracy: 0.8394\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4790 - accuracy: 0.8333\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4811 - accuracy: 0.8273\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4514 - accuracy: 0.8455\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4353 - accuracy: 0.8667\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4600 - accuracy: 0.8394\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4430 - accuracy: 0.8424\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4559 - accuracy: 0.8515\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4272 - accuracy: 0.8697\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4525 - accuracy: 0.8182\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4197 - accuracy: 0.8667\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4392 - accuracy: 0.8424\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4606 - accuracy: 0.8455\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4352 - accuracy: 0.8424\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4458 - accuracy: 0.8455\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4136 - accuracy: 0.8697\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4222 - accuracy: 0.8545\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4237 - accuracy: 0.8606\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4199 - accuracy: 0.8758\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4363 - accuracy: 0.8576\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4064 - accuracy: 0.8818\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3937 - accuracy: 0.8667\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3946 - accuracy: 0.8758\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4115 - accuracy: 0.8697\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3950 - accuracy: 0.8667\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3862 - accuracy: 0.8636\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3891 - accuracy: 0.8697\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3801 - accuracy: 0.8909\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3984 - accuracy: 0.8758\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3838 - accuracy: 0.8758\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3891 - accuracy: 0.8697\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3788 - accuracy: 0.8667\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3935 - accuracy: 0.8697\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3808 - accuracy: 0.8727\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3811 - accuracy: 0.8636\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3942 - accuracy: 0.8455\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3744 - accuracy: 0.8788\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3902 - accuracy: 0.8667\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3818 - accuracy: 0.8758\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3932 - accuracy: 0.8667\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3938 - accuracy: 0.8515\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3684 - accuracy: 0.8788\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3641 - accuracy: 0.8818\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3758 - accuracy: 0.8727\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3836 - accuracy: 0.8394\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3639 - accuracy: 0.8667\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3590 - accuracy: 0.8818\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3546 - accuracy: 0.8879\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3546 - accuracy: 0.8909\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3527 - accuracy: 0.8848\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3678 - accuracy: 0.8697\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3456 - accuracy: 0.8788\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3575 - accuracy: 0.8788\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3767 - accuracy: 0.8636\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3350 - accuracy: 0.8939\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3479 - accuracy: 0.8697\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3470 - accuracy: 0.8879\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3409 - accuracy: 0.8909\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3395 - accuracy: 0.8727\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3424 - accuracy: 0.8970\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3568 - accuracy: 0.8636\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3458 - accuracy: 0.8727\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3345 - accuracy: 0.8939\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3362 - accuracy: 0.8939\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3335 - accuracy: 0.8727\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3137 - accuracy: 0.8970\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3171 - accuracy: 0.8909\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3609 - accuracy: 0.8758\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3285 - accuracy: 0.9000\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3195 - accuracy: 0.8788\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.3371 - accuracy: 0.8909\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3154 - accuracy: 0.8818\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3233 - accuracy: 0.8848\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3262 - accuracy: 0.8939\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3165 - accuracy: 0.8939\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3050 - accuracy: 0.9000\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3129 - accuracy: 0.8909\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2990 - accuracy: 0.9061\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2996 - accuracy: 0.9000\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3166 - accuracy: 0.8879\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2997 - accuracy: 0.9000\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3100 - accuracy: 0.8879\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3090 - accuracy: 0.8939\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3160 - accuracy: 0.9000\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3009 - accuracy: 0.8970\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3009 - accuracy: 0.8727\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2922 - accuracy: 0.8970\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3067 - accuracy: 0.9061\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3066 - accuracy: 0.9030\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3035 - accuracy: 0.8667\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3073 - accuracy: 0.8788\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2842 - accuracy: 0.8909\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2850 - accuracy: 0.8818\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2946 - accuracy: 0.8939\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2908 - accuracy: 0.8939\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2971 - accuracy: 0.8879\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.3031 - accuracy: 0.8909\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2880 - accuracy: 0.9061\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2967 - accuracy: 0.8727\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2853 - accuracy: 0.8848\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2772 - accuracy: 0.9030\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2645 - accuracy: 0.9061\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2795 - accuracy: 0.8788\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2739 - accuracy: 0.9030\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2687 - accuracy: 0.9091\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2844 - accuracy: 0.8848\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2718 - accuracy: 0.9030\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2706 - accuracy: 0.8879\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2809 - accuracy: 0.8909\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2714 - accuracy: 0.9182\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2792 - accuracy: 0.9061\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2754 - accuracy: 0.8848\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2736 - accuracy: 0.8879\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2608 - accuracy: 0.9000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2830 - accuracy: 0.9061\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2750 - accuracy: 0.9000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2744 - accuracy: 0.8909\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2815 - accuracy: 0.9000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2736 - accuracy: 0.8879\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2705 - accuracy: 0.9030\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2737 - accuracy: 0.8970\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2513 - accuracy: 0.8970\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2750 - accuracy: 0.8939\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2663 - accuracy: 0.8939\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2631 - accuracy: 0.9030\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2633 - accuracy: 0.8939\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2433 - accuracy: 0.9061\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.2778 - accuracy: 0.8970\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2505 - accuracy: 0.9061\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2362 - accuracy: 0.9182\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2470 - accuracy: 0.9273\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2529 - accuracy: 0.8939\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2476 - accuracy: 0.9000\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.2487 - accuracy: 0.9030\n"
          ]
        }
      ],
      "source": [
        "train = model.fit(x_train, y_train, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Tun-lFwyGvA5",
        "outputId": "a037b564-739b-499e-fa06-d2dee95470ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x274402dc700>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train.history['accuracy'], label='training set accuracy')\n",
        "plt.plot(train.history['loss'], label='trainig set loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "xf4pnvfjsgHm",
        "outputId": "7cc51a23-181b-44b9-ca84-c45d9b719760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Otx0zNjQ-X"
      },
      "source": [
        "#Chatbot ü§ñ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Pjw-gEje9a",
        "outputId": "a164871f-31f1-4594-b491-89846d2ce4c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: hi\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "response=greeting\n",
            "Pocket Therapist:  Hello there. Tell me how are you feeling today?\n",
            "User: bye\n",
            "Goodbye and take care.\n"
          ]
        }
      ],
      "source": [
        "\"\"\" while True:\n",
        "  conversation = []\n",
        "  user_input = input('User: ')\n",
        "  if user_input == 'bye':\n",
        "    print('Goodbye and take care.')\n",
        "    break\n",
        "\n",
        "  # converting lowercase / removing punctuation \n",
        "  user_input = user_input.lower()\n",
        "  user_input = re.sub(r'[^\\w\\s]', '', user_input)\n",
        "  conversation.append(user_input)\n",
        "\n",
        "  # tokenizer / padding\n",
        "  user_input = tokenizer.texts_to_sequences(conversation)\n",
        "  user_input = np.array(user_input).reshape(-1)\n",
        "  user_input = pad_sequences([user_input], input_size)\n",
        "\n",
        "  # output\n",
        "  output = model.predict(user_input)\n",
        "  output = output.argmax()\n",
        "\n",
        "  # prediction\n",
        "  response = encoder.inverse_transform([output])[0]\n",
        "  print('response=' + response)\n",
        "  if response in responses:\n",
        "    print('Pocket Therapist: ', random.choice(responses[response]))\n",
        "  else:\n",
        "    print('Sorry, I do not understand. Can you please rephrase?')\n",
        "  if response == 'goodbye':\n",
        "    break \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model/assets\n"
          ]
        }
      ],
      "source": [
        "model.save(filepath='./saved_model/', include_optimizer=True, overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('mindmate_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfj1S++BgK4adIe4e88ScI",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "dc40aa98bc857e6b44b78fb1f886858e51ffa17b4908ef3c7ccadfa45af47b27"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
